{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Final Project </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ __ We first download load the data __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df_reviews = pd.DataFrame()\n",
    "file_list = os.listdir(\"../reviews.json\")\n",
    "\n",
    "for file in file_list:\n",
    "    # loading the reviews into a dataframe\n",
    "    df = pd.read_json(\"../reviews.json/\" + file, lines=True)\n",
    "    df_reviews = pd.concat([df_reviews,df])\n",
    "\n",
    "# removing rows containing NaN value and reaffecting index to the df\n",
    "df_reviews = df_reviews.dropna() \n",
    "df_reviews = df_reviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the business into a dataframe\n",
    "df_business = pd.read_json(\"../yelp_dataset/yelp_academic_dataset_business.json\",lines=True) #lines=True to load a file with more than one line of JSON\n",
    "\n",
    "# removing rows containing NaN value and reaffecting index to the df\n",
    "df_business = df_business.dropna() \n",
    "df_business = df_business.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews keys :  ['business_id', 'date', 'review_id', 'stars', 'text', 'user_id']\n",
      "Business keys :  ['address', 'attributes', 'business_id', 'categories', 'city', 'hours', 'is_open', 'latitude', 'longitude', 'name', 'neighborhood', 'postal_code', 'review_count', 'stars', 'state']\n"
     ]
    }
   ],
   "source": [
    "print(\"Reviews keys : \", list(df_reviews.keys()))\n",
    "print(\"Business keys : \", list(df_business.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ __ The idea is now to filter the business dataframe in order to select only the business that have reviews__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['LHXisknIbUy_XtdEQc7x9w', '2NsEac9xCBI05bo5l4yI7Q', '-2ToCaDFpTNmmg3QFzxcWg', '8nmjvYX4N67cxOsGfbEgjg', 'v9u0NgjA4iQeKGevFnYSCA', 'of4V8nfW7GwJ03tLDdrOlA', 'hRK876bEBdPYAJKbg6pCEw', 'ho1vUk9R7Ole9aNmX6NMDA', 'X-b4-QvZLENnf3yFwhpSXQ', 'kamKFAkLzH-mXx5QmvCefg', 'a8ACgZ_bPPT6iRQ6R7Ridg', 'OFnDWBP8iXxgeBrfHA5fRA']\n"
     ]
    }
   ],
   "source": [
    "list_business = list(df_reviews.business_id.unique())\n",
    "\n",
    "# selecting only the wanted business\n",
    "df_business = df_business[df_business['business_id'].isin(list_business)]\n",
    "df_business = df_business.reset_index(drop=True)\n",
    "\n",
    "# strange thing : the two following lists do not have the same length\n",
    "print(len(list_business) - len(df_business))\n",
    "print(list(set(list_business) - set(list(df_business.business_id.values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze comment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "labMT = pd.read_csv('data/s001.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function computing the sentimental value of a text\n",
    "def computeSentiment(text):\n",
    "    happiness_average, text = 0, word_tokenize(text)\n",
    "    words = {word: text.count(word) for word in set(text)}\n",
    "    \n",
    "    for word in words:\n",
    "        val_happiness = labMT[labMT[\"word\"] == word].happiness_average.values\n",
    "        # checking if the word is in labMT or not\n",
    "        if len(val_happiness)>0:\n",
    "            happiness_average += float(val_happiness[0]) * words[word] # taking into account the nb of occurences of the word\n",
    "            \n",
    "    return happiness_average / len(text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ __Now creating a dictionnary where keys are business id and value a list of all the comments related to this business. In order to compute the rating of each business. And another one where keys are business id and values the sentiment value__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_reviews = {business: [] for business in list_business}\n",
    "\n",
    "for i in range(len(df_reviews)):\n",
    "    comment = df_reviews.loc[i].text\n",
    "    business = df_reviews.loc[i].business_id\n",
    "    \n",
    "    dic_reviews[business].append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "dic_rate = {}\n",
    "\n",
    "for elt in list(dic_reviews.keys())[:20]:\n",
    "    dic_rate[elt] = mean([computeSentiment(text) for text in dic_reviews[elt]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing positions on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering business in order to get business in a small area\n",
    "df_business[\"latitude\"] = pd.to_numeric(df_business[\"latitude\"]) # changing type of the column to float\n",
    "df_business[\"longitude\"] = pd.to_numeric(df_business[\"longitude\"])\n",
    "\n",
    "# df_business = df_business[(df_business[\"longitude\"] > -90) & (df_business['longitude'] < -85) &(df_business['latitude'] < 42)]\n",
    "# df_business = df_business.reset_index(drop=True)\n",
    "# print(len(df_business))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use either one of the following locations :\n",
    "<li> First one gets all business locations </li>\n",
    "<li> Second one gets only the locations of the business which sentimental mark is computed</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n"
     ]
    }
   ],
   "source": [
    "# creating a list containing all localisations of business\n",
    "locations = []\n",
    "for i in range(len(df_business)):\n",
    "    locations.append((df_business.loc[i].latitude, df_business.loc[i].longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list containing the localisations of all the analyzed business\n",
    "locations = []\n",
    "for business in list(dic_rate.keys()):\n",
    "    locations.append((df_business[df_business['business_id'] == business].latitude.values[0], df_business[df_business['business_id'] == business].longitude.values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(198, 57, 0, 0.5), (94, 161, 0, 0.5), (233, 22, 0, 0.5), (0, 255, 0, 0.5), (173, 82, 0, 0.5), (95, 160, 0, 0.5), (179, 76, 0, 0.5), (255, 0, 0, 0.5), (118, 137, 0, 0.5), (177, 78, 0, 0.5), (125, 130, 0, 0.5), (42, 213, 0, 0.5), (76, 179, 0, 0.5), (191, 64, 0, 0.5), (145, 110, 0, 0.5), (232, 23, 0, 0.5), (136, 119, 0, 0.5), (217, 38, 0, 0.5), (173, 82, 0, 0.5), (193, 62, 0, 0.5)]\n"
     ]
    }
   ],
   "source": [
    "# here we compute the color of each marker (business) regarding their final mark\n",
    "list_rates = list(dic_rate.values())\n",
    "\n",
    "def aggregateColors(rate):\n",
    "    x = int(255*(rate - min(list_rates))/(max(list_rates) - min(list_rates)))\n",
    "    return (255 - x, x, 0, 0.5)\n",
    "\n",
    "colors = [aggregateColors(elt) for elt in rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddc7c64dab8443197e95bb1c2f5f3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gmaps\n",
    "gmaps.configure(api_key='API_KEY')\n",
    "\n",
    "fig = gmaps.figure()\n",
    "symbols = gmaps.symbol_layer(\n",
    "        locations, fill_color=colors, stroke_color=colors)\n",
    "fig.add_layer(symbols)\n",
    "\n",
    "# hm = gmaps.heatmap_layer(locations, weights=rate, max_intensity=max(rate), point_radius=5.0)\n",
    "# fig.add_layer(hm)\n",
    "\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
