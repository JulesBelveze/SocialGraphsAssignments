{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Final Project </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ __ We first download load the data __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474432\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df_reviews = pd.DataFrame()\n",
    "file_list = os.listdir(\"../yelp_dataset/reviews_filter.json\")\n",
    "\n",
    "for file in file_list:\n",
    "    # loading the reviews into a dataframe\n",
    "    df = pd.read_json(\"../yelp_dataset/reviews_filter.json/\" + file, lines=True) #specify that json has multiple lines\n",
    "    df_reviews = pd.concat([df_reviews, df])\n",
    "\n",
    "# removing rows containing NaN value and reaffecting index to the df\n",
    "df_reviews = df_reviews.dropna() \n",
    "df_reviews = df_reviews.reset_index(drop=True)\n",
    "\n",
    "print(len(df_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108521\n"
     ]
    }
   ],
   "source": [
    "# loading the business into a dataframe\n",
    "df_business = pd.DataFrame()\n",
    "file_list = os.listdir(\"../yelp_dataset/open_business.json\")\n",
    "    \n",
    "for file in file_list:\n",
    "    # loading business into a dataframe\n",
    "    df = pd.read_json(\"../yelp_dataset/open_business.json/\" + file, lines=True) #specify that json has multiple lines\n",
    "    df_business = pd.concat([df_business, df])\n",
    "\n",
    "# removing rows containing NaN value and reaffecting index to the df\n",
    "df_business = df_business.dropna() \n",
    "df_business = df_business.reset_index(drop=True)\n",
    "\n",
    "print(len(df_business))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reviews keys : \", list(df_reviews.keys()))\n",
    "print(\"Business keys : \", list(df_business.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ __ The idea is now to filter the business dataframe in order to select only the business that have reviews__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8191\n",
      "7799\n"
     ]
    }
   ],
   "source": [
    "list_business = list(df_reviews.business_id.unique())\n",
    "print(len(list_business))\n",
    "\n",
    "# selecting only the wanted business\n",
    "df_business = df_business[df_business['business_id'].isin(list_business) == True]\n",
    "df_business = df_business.reset_index(drop=True)\n",
    "print(len(df_business))\n",
    "\n",
    "# strange thing : the two following lists do not have the same length\n",
    "# print(len(list_business) - len(df_business))\n",
    "# print(list(set(list_business) - set(list(df_business.business_id.values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze comment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "labMT = pd.read_csv('data/s001.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function computing the sentimental value of a text\n",
    "def computeSentiment(text):\n",
    "    happiness_average, text = 0, word_tokenize(text)\n",
    "    words = {word: text.count(word) for word in set(text)}\n",
    "    \n",
    "    for word in words:\n",
    "        val_happiness = labMT[labMT[\"word\"] == word].happiness_average.values\n",
    "        # checking if the word is in labMT or not\n",
    "        if len(val_happiness)>0:\n",
    "            happiness_average += float(val_happiness[0]) * words[word] # taking into account the nb of occurences of the word\n",
    "            \n",
    "    return happiness_average / len(text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ __Now creating a dictionnary where keys are business id and value a list of all the comments related to this business. In order to compute the rating of each business. And another one where keys are business id and values the sentiment value__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_reviews = {business: [] for business in list_business}\n",
    "\n",
    "for i in range(len(df_reviews)):\n",
    "    comment = df_reviews.loc[i].text\n",
    "    business = df_reviews.loc[i].business_id\n",
    "    \n",
    "    dic_reviews[business].append(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet$ __ Use the first cell to create a json file containing as a key the business id and as value the rate of the busines. Use the second one to load the data from the file.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from statistics import mean\n",
    "dic_rate = {}\n",
    "\n",
    "for elt in list(dic_reviews.keys()):\n",
    "    dic_rate[elt] = mean([computeSentiment(text) for text in dic_reviews[elt]])\n",
    "\n",
    "with open(\"dic_rate.json\",'w') as file:\n",
    "    json.dump(dic_rate, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing positions on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering business in order to get business in a small area\n",
    "df_business[\"latitude\"] = pd.to_numeric(df_business[\"latitude\"]) # changing type of the column to float\n",
    "df_business[\"longitude\"] = pd.to_numeric(df_business[\"longitude\"])\n",
    "\n",
    "# df_business = df_business[(df_business[\"longitude\"] > -90) & (df_business['longitude'] < -85) &(df_business['latitude'] < 42)]\n",
    "# df_business = df_business.reset_index(drop=True)\n",
    "# print(len(df_business))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use either one of the following locations :\n",
    "<li> First one gets all business locations </li>\n",
    "<li> Second one gets only the locations of the business which sentimental mark is computed</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list containing all localisations of business\n",
    "locations = []\n",
    "for i in range(len(df_business)):\n",
    "    locations.append((df_business.loc[i].latitude, df_business.loc[i].longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list containing the localisations of all the analyzed business\n",
    "locations = {}\n",
    "for business in list(dic_rate.keys()):\n",
    "    try:\n",
    "        locations[business] =((df_business[df_business['business_id'] == business].latitude.values[0], df_business[df_business['business_id'] == business].longitude.values[0]))\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7799\n",
      "7799\n"
     ]
    }
   ],
   "source": [
    "# here we compute the color of each marker (business) regarding their final mark\n",
    "max_rate = max(dic_rate.values())\n",
    "min_rate = min(dic_rate.values())\n",
    "def aggregateColors(rate):\n",
    "    x = int(255*(rate - min_rate)/(max_rate - min_rate))\n",
    "    return (255 - x, x, 0, 0.8)\n",
    "\n",
    "colors = [aggregateColors(dic_rate[elt]) for elt in list(locations.keys())]\n",
    "print(len(locations))\n",
    "print(len(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gmaps\n",
    "# gmaps.configure(api_key='API_KEY')\n",
    "\n",
    "# place_focus = (33.448376, -112.074036) #focusing on phenix\n",
    "# fig = gmaps.figure(\n",
    "#         center = place_focus,\n",
    "#         zoom_level = 10)\n",
    "# symbols = gmaps.symbol_layer(\n",
    "#         list(locations.values()), \n",
    "#         fill_color=colors, \n",
    "#         stroke_color=colors)\n",
    "# fig.add_layer(symbols)\n",
    "\n",
    "# hm = gmaps.heatmap_layer(locations, weights=rate, max_intensity=max(rate), point_radius=5.0)\n",
    "# fig.add_layer(hm)\n",
    "\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
